# 公告 {#concept_nft_ztv_rfb .concept}

本文为您介绍实时计算公告内容，包括版本更新、功能更新、产品活动等。

## 版本发布`blink-2.2.7` {#section_zy1_xlf_4gb .section}

公告时间：`2019-01-24`

`blink-2.2.7`是`blink-2.x`系列中最新稳定版本，在`blink-1.x`版本（最新稳定版本为`blink-1.6.4`）进行了全面的升级，采用了自主研发的新一代存储Niagara作为Statebackend的底层存储，优化了SQL的性能，增加了一系列新功能。

-   主要特性
    -   SQL
        -   新增Window Emit机制，可以控制window结果的输出策略，如：1小时窗口，每1分钟输出一次。
        -   双流join在功能上支持了miniBatch，针对不同场景优化了retraction处理和state存储结构，提高了性能。
        -   AGG 支持 Filter 语法，可以只聚合满足条件的行。
        -   对Local-global AGG进行优化。
        -   重构了SQL的optimize阶段，解决了SQL编译时间过长的若干问题。
        -   增加了对SortedMapView中key的多种数据类型的支持：Boolean、 Byte、Short、In、Long、Float、Double、BigDecimal、BigInt、byte\[\]和String。
        -   优化了min/max/first/last等在有retraction场景时的性能。
        -   新增若干标量函数，例如时区相关的解析、格式化、转换函数： TO\_TIMESTAMP\_TZ、DATE\_FORMAT\_TZ和CONVERT\_TZ。
        -   对SQL，Connector模块的错误信息进行了归类，并对每种类型设计了相应的ERROR\_CODE。
    -   Connector
        -   支持用户自定义的tableFactory方式注册source和sink插件。
        -   支持用户通过udtf方式直接解析数据源类型。
        -   支持读取和写入kafka。
        -   支持写入到ElasticSearch。
    -   Runtime
        -   通过Blink Session机制，统一了用户提交Job、获取执行结果等行为。
        -   开放了调度插件机制，允许计算模型根据需求自定义调度逻辑。
        -   在有限流的情况下，通过避免不必要的全图重启，提高了JM和Task FailOver的效率。
    -   StateBackend
        -   使用NiagaraStateBackend替换RocksdbStateBackend，具备更好的读写性能。
        -   `(Experimental) NiagaraStateBackend`支持计算存储分离，支持failover过程中state秒级恢复
-   **与`blink1.6.4`不兼容的语法**

    |功能项|影响|解决办法|
    |---|--|----|
    |TableFunction接口修改|所有使用自定义TableFunction的用户|更新代码，实现新的getResultType接口|
    |ScalarFunction接口修改|所有使用自定义ScalarFunction的用户|实现新的getResultType接口|
    |AggregateFunction接口修改|所有使用自定义AggregateFunction的用户|实现新的getAccumulatorType和getResultType接口。例如 ACC类型为`Row(String, Long)`， Agg result的类型为String 则需要实现：    ```
public DataType getAccumulatorType\(\) { return
              DataTypes.createRowType\(DataTypes.String, DataTypes.LONG\); } public DataType
              getResultType\(\) { return DataTypes.String; }
    ```

|
    |MapView构造函数修改|MapView构造函数形参类型由之前的TypeInformation变更为了DataType。所以在自定义udaf中声明了MapView的job都会受影响。|更新代码，按DataType去构造MapView。比如`MapView map = new MapView<>(Types.STRING, Types.INT);`得更新为`MapView map = new MapView<>(DataTypes.STRING, DataTypes.INT);`|
    |当参数是long、int 时，除法和AVG返回类型改为了double|以前的除法和AVG返回的是参数类型，现在是double，会导致类型不匹配的错误。例如：除法/AVG的结果直接写入结果表，可能会报结果表与query的字段类型不匹配的错误。|在除法/AVG 的结果上强制加上CAST 。|
    |BigDecimalTypeInfo现在在比较时会考虑精度|用到Decimal的 job，可能会抛BigDecimal 类型不匹配的问题。|用到Decimal 类型的job，全局替换成带精度的声明方式，`Decimal(38, 18)`|
    |NULL与字符串的比较语义|`1.x`版本NULL与字符串比较返回true，在`2.x`版本后遵循了数据库语义改为返回false。|所有NULL与字符串比较的地方，例如：`WHERE SPLIT_INDEX(shop_list, ':', 1) <> shop_id`，如果`SPLIT_INDEX(shop_list, ':', 1)`返回了NULL，在`1.x`版本上where条件会返回true，在`2.x`上面会返回false将数据过滤。|

-   **如何升级到`blink-2.x`**

    使用`blink-1.x`版本的job升级到`blink-2.x`，需要进行数据回溯升级，数据回溯是指用户根据业务需要，在启动job时候指定启动位点，具体操作如下：

    1.  停止待升级job（清除state）；
    2.  开发界面点击右下角的**测试版本**，修改job的blink版本为`blink-2.2.7`，上线job；
    3.  启动修改后的job并指定启动位点；
    4.  若步骤3不成功，人工介入查明原因后，做如下操作：
    5.  可以快速修复sql，重复步骤1，2，3；
    6.  无法修复sql，回退到原有blink版本;
    7.  如遇上无法生成json plan的情况，可以尝试设置如下参数：
        -   `blink.job.option.jmMemMB=4096`
        -   `blink.job.submit.timeoutInSeconds=600`
    **说明：** 

    `blink-2.0.1`的udx第三方插件安装包，请参见[UDX概述](../../../../../cn.zh-CN/使用指南/Flink SQL/自定义函数（UDX）/UDX概述.md#)：

    如果遇到类似如下的异常，是因为udx包的版本太低或者包冲突导致：

    ```
    code:[30016], brief info:[get app plan failed], context info:[detail:[java.lang.NoClassDefFoundError: org/apache/flink/table/functions/aggfunctions/DoubleSumWithRetractAggFunction
    at java.lang.ClassLoader.defineClass1(Native Method)
    at java.lang.ClassLoader.defineClass(ClassLoader.java:788)
    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)
    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
    ```


## 版本发布 {#section_xnr_wvv_rfb .section}

-   公告时间

    `2018-05-29 16:00:00`

-   公告内容

    实时计算为了给用户带来更好的开发交互体验,将于明日19:00上线新版本。更新内容如下。

    总览

    新功能

    -   Job overview 页面增加SQL物理执行计划展示。
    -   为window算子增加每分钟丢弃数据量的metric汇报。
    -   支持In、exist、not in、not exist，并转换为semi-anti join执行。
    -   使用英文显示Job launch 的错误信息。
    -   所有的sink插件支持ignoreDelete参数。
    -   ads支持ak和sk参数来替代userName/passWord。
    -   支持[引擎版本切换](../../../../../cn.zh-CN/使用指南/数据开发/开发阶段.md#section_zg2_cgs_2gb)
-   Bug修复
    -   修复 first\_value/last\_value 第一个字段为null的异常。
    -   修复了ots维表获取pk字段的bug。
    -   修复了智能配置根据metrics判断failover信息不准确的bug。
    -   修复cast比较时出现ClassCastException的bug。
    -   修复LogicalTableFunctionCall错误的继承结构引起的分段优化错误。
    -   修复TopN与OVER语法的规则匹配问题。
    -   修复了connector open阶段增加并发度检查时抛出IndexOutOfArrayLength异常的bug。
    -   修复阿里云sts过期导致的failover问题。
    -   修复同一个container内同时存在多个sink时可能会出现的插入异常。
    -   修复rds mysql sink不支持插入关键字的bug。

## 公测用户转正式商用最后一次通知 {#section_y2m_xgw_rfb .section}

-   公告时间

    `2018-05-08 15:00:00`

-   公告内容

    实时计算已于2018年4月30日完成正式商用，但发现部分有使用需求的公测用户仍未付费购买。为确保您能继续使用实时计算，请务必在5月15日前完成付费并绑定到原有项目上，否则将视为放弃使用实时计算，我们将释放其占有的全部计算资源，并清空项目空间。因此造成的一切损失由客户自行承担。


## 公测用户转正式商用 {#section_a1x_fhw_rfb .section}

-   公告时间

    `2018-04-23 16:00:00`

-   公告内容

    实时计算已于2018年4月1日正式商用，公测用户有一个月的缓冲期，须在4月内付费并绑定到原有项目上。如果您还有继续使用实时计算的需求，请务必在4月内未进行购买并绑定，否则将视为放弃使用实时计算，我们将释放其占有的全部计算资源，并清空项目空间。另外，购买时可以根据目前CU的使用量来购买。比如，公测申请了50个CU，但实际使用了20个CU，那么购买只用购买20个CU即可。如果目前使用了50个CU，只购买了10个CU，那么会导致您的作业随时有被强行停止的风险。您如果有任何问题，欢迎及时反馈。


## 实时计算首次大优惠，包年8.5折 {#section_dry_grw_rfb .section}

-   公告时间

    `2018-04-20 6:00:00`

-   公告内容

    包年8.5折

    ![](images/21678_zh-CN_source.jpg)


## 新版本上线 {#section_axr_ksw_rfb .section}

-   公告时间

    `2018-04-19 17:20:00`

-   公告内容

    实时计算为了给用户带来更好的开发交互体验,将于今日`19:00`上线新版本。

    更新内容如下。

    总览界面

    -   增加新版本功能提示。
    -   CU使用率超过90%时增加扩容提示。
    -   增加剩余可使用时间，少于30天时提示续费。
    -   增加项目信息，包括管理员、用户、地域、创建时间等信息，管理员可以直接在总览页面管理项目
    -   增加新手指导部分
    开发界面

    -   文件树

        -   重新设计了底层逻辑
        -   支持拖拽移动文件夹
        -   支持拖拽移动文件
        -   支持非弹窗快速修改文件夹名称
        -   右键菜单根据窗口边界自动适应
        -   增加快捷操作列表
        详情请参看[开发阶段](../../../../../cn.zh-CN/使用指南/数据开发/开发阶段.md#)

    -   数据源
        -   重写了数据源逻辑
        -   数据源数据抽样与血缘关系数据抽样打通
    -   运行引擎
        -   Blink版本的下拉列表宽度自适应，不再需要拖拽宽度
    -   代码界面
        -   支持错误提示精确到字符
        -   所有不可进行操作（调试、运维）等按钮增加不可操作原因的提示
        -   增加沉浸式全屏编辑模式
        -   PlanJSON编辑页面重新设计支持一键切换到代码模式，优化了现有展示方式，不再会被遮挡。
        -   作业版本增加对比、回滚、删除按钮，增加每次上线原因的提示
        -   文件对比JSON与配置部分重写高亮效果
        -   语法检查错误提示支持高亮
    -   调试

        -   支持顺序抽样功能
        -   调试数据预览与结果固定表头
        详情请参看[调试阶段](../../../../../cn.zh-CN/使用指南/数据开发/调试阶段.md#)

    运维界面

    -   运维列表

        -   增加了资源消耗的排序和显示
        -   批量操作模式下禁止了无关操作的可能性
        -   运行模式筛选方式改变
        -   新作业提交的提示方式修改
        -   作业启动时增加透明升级部分的操作逻辑
        更多详情请参见[数据运维](../../../../../cn.zh-CN/使用指南/数据运维/作业状态.md#)

    -   Vertex列表
        -   重新设计了Vertex拓扑的布局方式，目前的排列更加规则整齐
        -   Vertex列表固定了ID和Task状态在首尾两列
        -   增加切换视图选项，可以将Vertex Name和数据展示方式进行切换
    -   Vertex详情
        -   重新设计了拓扑结构，按照RecIn和RecOut来判断拓扑是否有错误
        -   重命名了之前不合理的Tab名称
        -   SubTask List 移除了TaskContainer的跳转 ，增加查看历史的提示
        -   历史曲线时间选择器固定在头部
    -   数据曲线
        -   重写了数据曲线逻辑，增强了拓展性
        -   重新设计了曲线自动刷新时的loading效果，及曲线的配色体系
        -   增加WaterMark曲线
        -   曲线的tooltip目前不再会在y方向被遮挡了
        -   固定时间选择器在用户始终可见的位置
    -   Failover
        -   最近一次的FailOver详情增加高亮效果
        -   FailOver历史列表优化，错误信息在展开后可见，增加高亮。
    -   JobManager
        -   增加Attempt List及直接跳转到Resource的方式
        -   增加当前的Metric列表，不再需要弹窗显示。
    -   血缘关系

        -   重新设计了血缘关系的展示方式
        -   数据抽样不再需要右键点击，在数据表直接点击即可抽样
        更多详情请参看[血缘关系](../../../../../cn.zh-CN/使用指南/数据运维/血缘关系.md#)

    -   告警设置

        -   优化了交互，用户现在可以更容易的添加告警规则了
    -   属性参数
        -   将原有Configration部分移入属性参数
        -   合并历史列表展示

## RDS连接报错解决方案 {#section_fsh_jww_rfb .section}

-   公告时间

    `2018-04-12 17:00:00`

-   公告内容

    添加实时计算白名单

    近期实时计算集群扩容，对于已经在实时计算中注册过的RDS用来说没影响，但有些用户可能未注册数据源而直接在sql中以代码的形式访问RDS，对于这部分用户，有可能出现无法访问RDS的错误。这是因为RDS系统出于自身安全的考虑，禁止了外部访问，所以需要这些用户在RDS系统中授权实时计算访问。如何添加RDS的白名单，请见[如何配置数据存储白名单](../../../../../cn.zh-CN/使用指南/数据存储/如何配置数据存储白名单.md#)。请在添加RDS白名单之后，进行数据源的注册，这样实时计算就能在扩容时自动添加白名单，避免出现链接错误。


