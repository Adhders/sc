# 开发 {#concept_tl4_psd_2hb .concept}

本文为您介绍Datastream作业开发POM依赖包、Datastream作业开发示例和Datastream Connector。

**说明：** 仅独享模式Blink3.x及以上版本，支持Flink Datastream功能。

建议使用IntelliJ IDEA中的maven工程进行Datastream作业开发。

## POM依赖包 {#section_vbg_14f_2hb .section}

请根据需求自行添加blink 3.2开源版本所支持的[POM依赖包](https://oss.sonatype.org/content/repositories/snapshots/com/alibaba/blink/)。

依赖示例如下。

``` { .language- .java}
<properties>
        <scala.version>2.11.12</scala.version>
        <scala.binary.version>2.11</scala.binary.version>
        <blink.version>blink-3.2.0-snapshot</blink.version>
        <java.version>1.8</java.version>
    </properties>

    <dependencies>
        <dependency>
            <groupId>com.alibaba.blink</groupId>
            <artifactId>flink-core</artifactId>
            <version>blink-3.2-SNAPSHOT</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>com.alibaba.blink</groupId>
            <artifactId>flink-java</artifactId>
            <version>blink-3.2-SNAPSHOT</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>com.alibaba.blink</groupId>
            <artifactId>flink-streaming-java_${scala.binary.version}</artifactId>
            <version>blink-3.2-SNAPSHOT</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-log4j12</artifactId>
            <version>1.7.7</version>
            <scope>runtime</scope>
        </dependency>
        <dependency>
            <groupId>log4j</groupId>
            <artifactId>log4j</artifactId>
            <version>1.2.17</version>
            <scope>runtime</scope>
        </dependency>
    </dependencies>
```

下载查看[完整依赖包示例](http://docs-aliyun.cn-hangzhou.oss.aliyun-inc.com/assets/attach/111995/cn_zh/1553501574644/pom.xml)。

## 作业示例 {#section_iml_tpf_2hb .section}

```language-java
public class Datastreamtest {
    public static void main(String[] args) throws Exception {

        // 创建 execution environment
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // 通过从本地txt文件读取数据
        //DataStream<String> text = env.readTextFile("./test.txt");
        DataStream<String> text = env.fromElements("hello world", "hello jason", "wonderful world");
        // 解析数据，按word分组，开窗，聚合
        DataStream<Tuple2<String, Integer>> windowCounts = text
                .flatMap(new FlatMapFunction<String, Tuple2<String, Integer>>() {
                    @Override
                    public void flatMap(String value, Collector<Tuple2<String, Integer>> out) {
                        for (String word : value.split("\\s")) {
                            out.collect(Tuple2.of(word, 1));
                        }
                    }
                })
                .keyBy(0)
                .timeWindow(Time.seconds(5))
                .sum(1);

        // 将结果打印到控制台，注意这里使用的是单线程打印，而非多线程
        windowCounts.print().setParallelism(1);

        env.execute("Socket Window WordCount");
    }

}
```

## Connector列表 {#section_hfc_xpf_2hb .section}

实时计算Flink 3.2版本新增Datastream Connector，列表如下。

-   Kafka
-   Kafka（开源版本）
-   Hbase（开源版本）
-   JDBC
-   RDS SINK
-   Elesticsearch
-   MongoDB
-   Redis

