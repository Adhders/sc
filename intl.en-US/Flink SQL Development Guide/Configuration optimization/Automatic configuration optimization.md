# Automatic configuration optimization {#concept_66930_zh .concept}

To improve user experience, the Realtime Compute team offers the automatic configuration optimization \(AutoConf\) feature.

## Background and scope {#section_g5m_wts_zfb .section}

To improve user experience, the Realtime Compute team offers the automatic configuration optimization \(AutoConf\) feature.

When all operators and input and output systems of your Realtime Compute job meet the performance requirements and are stable, AutoConf can help you properly adjust the job configuration, such as operator resources and parallelism. It also helps you address performance issues of your job throughout the entire process, such as low throughput and back pressure of data hotspot.

In the following scenarios, AutoConf can optimize job performance but cannot address the performance bottlenecks. To address the performance bottlenecks, manually configure your job or contact the technical support team of Realtime Compute.

-   Performance issues exist in the input or output systems of a Realtime Compute job.
    -   Performance issues in the data source, such as insufficient DataHub partitions and MQ throughput. In this case, you need to increase the partitions of the corresponding source table.
    -   Performance issues in the output sink, such as ApsaraDB for RDS deadlock.
-   Performance issues of [User Defined Extensions \(UDXs\)](intl.en-US/Flink SQL Development Guide/Flink SQL/UDX/UDX overview.md#) \(such as UDFs, UDAFs, and UDTFs\) of your Realtime Compute job.

## Operations {#section_mzn_c5s_zfb .section}

-   New jobs
    1.  Publish a job.
        1.  After you complete the SQL development and syntax check, click **Publish**. The **Publish New Version** page appears.****
        2.  Select Automatic CU Configuration for Resource Configuration. Use the default value for the first time.
            -   Automatic CU Configuration: AutoConf can generate an optimized resource configuration and assign a CU value based on the default configuration. If you run AutoConf for the first time, AutoConf generates an initial configuration based on empirical data. We recommend that you use AutoConf after your job has been properly running for 5 to 10 minutes and your job metrics, such as source RPS, have been stable for 2 to 3 minutes. Repeat this three to five times to obtain the optimal configuration.
            -   Use Latest Manually Configured Resources: The latest saved manual resource configuration is used. If the latest resource configuration was generated by AutoConf, the AutoConf configuration is used. If the latest resource configuration was done manually, the manual configuration is used.
    2.  Use the default configuration to start the job.

        1.  Use the default configuration to start the job.
        2.  Start the job.
        **Note:** Use automatic CU configuration after your job has been properly running for more than 10 minutes, and your job metrics, such as source RPS, have been stable for 2 to 3 minutes.

    3.  Use the custom configuration to start the job.
        1.  Fine-tune resource parameters.

            You can start the job in AutoConf mode after you manually set the number of CUs \(example: 40\). You can increase or decrease the number of CUs based on the actual status of the job to optimize the performance.

            -   Minimum number of CUs

                We recommend that you set the number of CUs to a value that is greater than or equal to 50% of the default value. The minimum number of CUs is 1. If the default value assigned by the automatic configuration is 71, we recommend that you set the minimum number of CUs to 36. 71 CUs Ã— 50% = 35.5 CUs.

            -   Increase the number of CUs

                If the throughput of your Realtime Compute job is lower than your expectation, try to increase the number of CUs. We recommend that you increase the number of CUs by at least 30% of the existing value. For example, if the existing value is 10, you can increase the number to 13.

            -   Repeat the optimization process

                If one optimization attempt cannot achieve the desired performance, try it more times. You can increase or decrease the number of resources based on the job status after each optimization attempt.

        2.  View the result of the optimization in**Administration** \> **Overview** \> **Consumed CUs** .

            **Note:** If you are performing automatic configuration on a new job, do not select Use Latest Manually Configured Resources. Otherwise, an error message is displayed.

-   Existing jobs
    -   Schematic diagram of the optimization process

        ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/41063/155764133233883_en-US.png)

        **Note:** 

        1.  Before performing automatic configuration on an existing job, check whether stateful operations are involved. This is because the saved state information of a job may be cleared during the automatic configuration process.
        2.  If your job is changed, for example, an SQL statement is modified or the Realtime Compute version is changed, the automatic configuration may fail. The reason is that these changes may lead to topology changes, which further results in certain issues. For example, curve charts do not display the latest data, or the state cannot be used for fault tolerance. In this case, resource configuration cannot be optimized based on the job running history. An error will be returned when you perform automatic configuration. You need to take the changed job as a new job, and repeat the previous operations.
    -   Procedure
        1.  Suspend the job.
        2.  Repeat the optimization procedure for a new job on this job, and use the latest configuration to start the job.

## FAQ { .section}

The result of automatic configuration may be compromised in the following scenarios:

-   The job runs only for a short period. Only limited useful information can be collected during data sampling. This reduces the accuracy of the results that are computed based on the AutoConf algorithm. We recommend that you prolong the running duration of the job and wait until your job metrics, such as source RPS, are stable for 2 to 3 minutes.
-   The job has encountered a failover. This reduces the accuracy of the results. We recommend that you check and handle failovers before performing automatic configuration.
-   Only a small amount of data is available for the job. This reduces the accuracy of the results. We recommend that you trace more historical data.
-   Affected by many factors, the configuration obtained by using the automatic configuration feature is not always better than the one that was generated the last time. If the automatic configuration feature cannot meet your needs for improving the job performance, manually optimize the configuration. For more information, see [Manual configuration optimization](intl.en-US/Flink SQL Development Guide/Configuration optimization/Manual configuration optimization.md#).

## Recommendations { .section}

-   Before performing automatic configuration on a job, ensure that the job has been running stably and properly for more than 10 minutes. This is helpful to collect accurate job running information for performing automatic configuration.
-   You may need to perform automatic configuration for three to five times before the job performance is significantly improved. Therefore, you need to repeat the publishing and O&M operations multiple times.
-   When you use AutoConf, you can specify the start offset to read data from the past or even stack up large amounts of data for a job. This allows you to easily and quickly view the configuration optimization results.

## Method for determining the effectiveness of automatic configuration { .section}

The AutoConf feature for Realtime Compute is enabled based on a JSON configuration file. After performing automatic configuration optimization, you can view the JSON configuration file to check whether this feature is running properly.

-   You can view the JSON configuration file by using either of the following methods:

    1.  View the file on the Development by click **Versions** \> **More** \> **Compare** \> **Configuration Comparison**.

        ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/41063/155764133233886_en-US.png)

    2.  View the file on the job Administration by click **Properties and Parameters** \> **Resource Configuration** \> ****.

        ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/41063/155764133233887_en-US.png)

-   JSON configuration description

    ```language-xml
    "autoConfig" : {
        "goal": {  // This indicates the goal of automatic configuration.
            "maxResourceUnits": 10000.0,  // This indicates the maximum number of CUs for a Blink job. The value cannot be modified, and you can ignore this item when checking whether the feature is running properly.
            "targetResoureUnits": 20.0  // This indicates the number of CUs that you have specified.
        },
        "result" : {  // This indicates the results of automatic configuration. This is very important.
          "scalingAction" : "ScaleToTargetResource",  // This indicates the action of automatic configuration. *
          "allocatedResourceUnits" : 18.5, // This indicates the total resources.
          "allocatedCpuCores" : 18.5,      // This indicates the total CPU cores.
          "allocatedMemoryInMB" : 40960    // This indicates the total memory size.
          "messages" : "xxxx"  // We recommend that you pay special attention to the displayed messages. *
        }
    }
    					
    ```

    -   scalingAction: The value of `InitialScale` indicates that automatic configuration is performed for the first time. The value of `ScaleToTargetResource` indicates that automatic configuration is not performed for the first time.
    -   If no message is displayed, the AutoConf feature is running properly. If some messages are displayed, you need to analyze the messages and handle the issues. Messages are categorized into the following two types:
        -   Warning: Messages of this type indicate that the feature is running properly, but you need to pay attention to potential issues, such as insufficient partitions of source tables.
        -   Error or exception: The `Previous job statistics and configuration will be used` error message appears, indicating that automatic configuration optimization fails. The automatic configuration for a job fails in either of the following two cases:
            -   The job or Blink version has been modified. In this case, the previous running information cannot be used for automatic configuration.
            -   The AutoConf algorithm encounters problems that need to be comprehensively analyzed based on relevant information and logs. This is often indicated by XxxException. If you do not have enough information to find out the cause of the failure, submit a ticket.

## Error messages { .section}

 **IllegalStateException** 

If the following error messages are displayed, the state cannot be used. To resolve this issue, terminate the job, clear its state, and then specify the start offset to re-read the data.****

If you cannot migrate the target job to a backup node and you are concerned that online business may be interrupted, click **Properties** on the right side of the **Development Platform**, roll back the target job to the previous version, and then specify the start offset to re-read the data during off-peak hours.

```
java.lang.IllegalStateException: Could not initialize keyed state backend.
    at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initKeyedState(AbstractStreamOperator.java:687)
    at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:275)
    at org.apache.flink.streaming.runtime.tasks.StreamTask.initializeOperators(StreamTask.java:870)
    at org.apache.flink.streaming.runtime.tasks.StreamTask.initializeState(StreamTask.java:856)
    at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:292)
    at org.apache.flink.runtime.taskmanager.Task.run(Task.java:762)
    at java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.flink.api.common.typeutils.SerializationException: Cannot serialize/deserialize the object.
    at com.alibaba.blink.contrib.streaming.state.AbstractRocksDBRawSecondaryState.deserializeStateEntry(AbstractRocksDBRawSecondaryState.java:167)
    at com.alibaba.blink.contrib.streaming.state.RocksDBIncrementalRestoreOperation.restoreRawStateData(RocksDBIncrementalRestoreOperation.java:425)
    at com.alibaba.blink.contrib.streaming.state.RocksDBIncrementalRestoreOperation.restore(RocksDBIncrementalRestoreOperation.java:119)
    at com.alibaba.blink.contrib.streaming.state.RocksDBKeyedStateBackend.restore(RocksDBKeyedStateBackend.java:216)
    at org.apache.flink.streaming.api.operators.AbstractStreamOperator.createKeyedStateBackend(AbstractStreamOperator.java:986)
    at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initKeyedState(AbstractStreamOperator.java:675)
    ... 6 more
Caused by: java.io.EOFException
    at java.io.DataInputStream.readUnsignedByte(DataInputStream.java:290)
    at org.apache.flink.types.StringValue.readString(StringValue.java:770)
    at org.apache.flink.api.common.typeutils.base.StringSerializer.deserialize(StringSerializer.java:69)
    at org.apache.flink.api.common.typeutils.base.StringSerializer.deserialize(StringSerializer.java:28)
    at org.apache.flink.api.java.typeutils.runtime.RowSerializer.deserialize(RowSerializer.java:169)
    at org.apache.flink.api.java.typeutils.runtime.RowSerializer.deserialize(RowSerializer.java:38)
    at com.alibaba.blink.contrib.streaming.state.AbstractRocksDBRawSecondaryState.deserializeStateEntry(AbstractRocksDBRawSecondaryState.java:162)
    ... 11 more
			
```

